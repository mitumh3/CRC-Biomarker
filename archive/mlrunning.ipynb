{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882bf6f0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.016446,
     "end_time": "2022-06-18T15:45:01.893989",
     "exception": false,
     "start_time": "2022-06-18T15:45:01.877543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03097ca4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T15:45:01.928139Z",
     "iopub.status.busy": "2022-06-18T15:45:01.927621Z",
     "iopub.status.idle": "2022-06-18T15:45:11.596715Z",
     "shell.execute_reply": "2022-06-18T15:45:11.595378Z"
    },
    "papermill": {
     "duration": 9.688822,
     "end_time": "2022-06-18T15:45:11.599111",
     "exception": false,
     "start_time": "2022-06-18T15:45:01.910289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import git\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "oauthkey = UserSecretsClient().get_secret('oauthkey')\n",
    "print(oauthkey)\n",
    "from git import Repo\n",
    "a = Repo.clone_from(\"https://\"+oauthkey+\"@github.com/mitumh3/CRC-FeatureSelection.git\", \"/kaggle/working/feature\")\n",
    "b = Repo.clone_from(\"https://\"+oauthkey+\"@github.com/mitumh3/CRC-FS-output.git\", \"/kaggle/working/output\")\n",
    "c = Repo.clone_from(\"https://\"+oauthkey+\"@github.com/mitumh3/CRC-usedF.git\", \"/kaggle/working/used\")\n",
    "!git config --global user.email \"truongngocminh0505@gmail.com\"\n",
    "!git config --global user.name \"mitumh3\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171a0d99",
   "metadata": {
    "papermill": {
     "duration": 0.009028,
     "end_time": "2022-06-18T15:45:11.617724",
     "exception": false,
     "start_time": "2022-06-18T15:45:11.608696",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# . Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96db15bd",
   "metadata": {
    "papermill": {
     "duration": 0.008492,
     "end_time": "2022-06-18T15:45:11.635167",
     "exception": false,
     "start_time": "2022-06-18T15:45:11.626675",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    ">>>Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501bc2e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T15:45:11.657073Z",
     "iopub.status.busy": "2022-06-18T15:45:11.656263Z",
     "iopub.status.idle": "2022-06-18T15:45:16.581260Z",
     "shell.execute_reply": "2022-06-18T15:45:16.580578Z"
    },
    "papermill": {
     "duration": 4.939214,
     "end_time": "2022-06-18T15:45:16.583940",
     "exception": false,
     "start_time": "2022-06-18T15:45:11.644726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Can get the functions\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.svm import SVC\n",
    "!pip install scikit-survival --no-dependencies\n",
    "from sksurv.compare import compare_survival\n",
    "# Ignore wanring\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b325caf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T15:45:16.619116Z",
     "iopub.status.busy": "2022-06-18T15:45:16.618121Z",
     "iopub.status.idle": "2022-06-18T15:45:33.098105Z",
     "shell.execute_reply": "2022-06-18T15:45:33.096731Z"
    },
    "papermill": {
     "duration": 16.501737,
     "end_time": "2022-06-18T15:45:33.101882",
     "exception": false,
     "start_time": "2022-06-18T15:45:16.600145",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pyblaze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06fa5c4",
   "metadata": {
    "papermill": {
     "duration": 0.017425,
     "end_time": "2022-06-18T15:45:33.137734",
     "exception": false,
     "start_time": "2022-06-18T15:45:33.120309",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    ">>>Basic process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b7a06b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T15:45:33.176079Z",
     "iopub.status.busy": "2022-06-18T15:45:33.175581Z",
     "iopub.status.idle": "2022-06-18T15:45:33.185103Z",
     "shell.execute_reply": "2022-06-18T15:45:33.184322Z"
    },
    "papermill": {
     "duration": 0.031808,
     "end_time": "2022-06-18T15:45:33.187686",
     "exception": false,
     "start_time": "2022-06-18T15:45:33.155878",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Basic process\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import statistics as s\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "import sys\n",
    "import ast\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed1e5f5",
   "metadata": {
    "papermill": {
     "duration": 0.017884,
     "end_time": "2022-06-18T15:45:33.223791",
     "exception": false,
     "start_time": "2022-06-18T15:45:33.205907",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    ">>>Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3667d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T15:45:33.260563Z",
     "iopub.status.busy": "2022-06-18T15:45:33.260124Z",
     "iopub.status.idle": "2022-06-18T15:45:33.264781Z",
     "shell.execute_reply": "2022-06-18T15:45:33.264007Z"
    },
    "papermill": {
     "duration": 0.025434,
     "end_time": "2022-06-18T15:45:33.266591",
     "exception": false,
     "start_time": "2022-06-18T15:45:33.241157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Method for normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d495e3",
   "metadata": {
    "papermill": {
     "duration": 0.016663,
     "end_time": "2022-06-18T15:45:33.300544",
     "exception": false,
     "start_time": "2022-06-18T15:45:33.283881",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    ">>>Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f19f6f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T15:42:06.223366Z",
     "iopub.status.busy": "2022-06-18T15:42:06.222926Z",
     "iopub.status.idle": "2022-06-18T15:42:06.830568Z",
     "shell.execute_reply": "2022-06-18T15:42:06.829574Z",
     "shell.execute_reply.started": "2022-06-18T15:42:06.223269Z"
    },
    "papermill": {
     "duration": 0.017049,
     "end_time": "2022-06-18T15:45:33.335699",
     "exception": false,
     "start_time": "2022-06-18T15:45:33.318650",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd159a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T15:45:33.373964Z",
     "iopub.status.busy": "2022-06-18T15:45:33.373454Z",
     "iopub.status.idle": "2022-06-18T15:45:33.378379Z",
     "shell.execute_reply": "2022-06-18T15:45:33.377259Z"
    },
    "papermill": {
     "duration": 0.027179,
     "end_time": "2022-06-18T15:45:33.380559",
     "exception": false,
     "start_time": "2022-06-18T15:45:33.353380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Can not get the functions\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d91c41",
   "metadata": {
    "papermill": {
     "duration": 0.017859,
     "end_time": "2022-06-18T15:45:33.416253",
     "exception": false,
     "start_time": "2022-06-18T15:45:33.398394",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    ">>>Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f3a4bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T15:45:33.455022Z",
     "iopub.status.busy": "2022-06-18T15:45:33.454329Z",
     "iopub.status.idle": "2022-06-18T15:45:33.459017Z",
     "shell.execute_reply": "2022-06-18T15:45:33.457987Z"
    },
    "papermill": {
     "duration": 0.027973,
     "end_time": "2022-06-18T15:45:33.462591",
     "exception": false,
     "start_time": "2022-06-18T15:45:33.434618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parameters optimization\n",
    "from sklearn.model_selection import GridSearchCV "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008c4875",
   "metadata": {
    "papermill": {
     "duration": 0.017979,
     "end_time": "2022-06-18T15:45:33.498878",
     "exception": false,
     "start_time": "2022-06-18T15:45:33.480899",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    ">>>Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599fdde4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T15:45:33.535433Z",
     "iopub.status.busy": "2022-06-18T15:45:33.534653Z",
     "iopub.status.idle": "2022-06-18T15:45:33.539066Z",
     "shell.execute_reply": "2022-06-18T15:45:33.538050Z"
    },
    "papermill": {
     "duration": 0.025261,
     "end_time": "2022-06-18T15:45:33.541530",
     "exception": false,
     "start_time": "2022-06-18T15:45:33.516269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Performance\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c457c03e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T15:42:49.271059Z",
     "iopub.status.busy": "2022-06-18T15:42:49.270662Z",
     "iopub.status.idle": "2022-06-18T15:42:52.406021Z",
     "shell.execute_reply": "2022-06-18T15:42:52.404411Z",
     "shell.execute_reply.started": "2022-06-18T15:42:49.270996Z"
    },
    "papermill": {
     "duration": 0.0184,
     "end_time": "2022-06-18T15:45:33.578145",
     "exception": false,
     "start_time": "2022-06-18T15:45:33.559745",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706b6e34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T15:45:33.616887Z",
     "iopub.status.busy": "2022-06-18T15:45:33.616138Z",
     "iopub.status.idle": "2022-06-18T15:45:35.454457Z",
     "shell.execute_reply": "2022-06-18T15:45:35.453396Z"
    },
    "papermill": {
     "duration": 1.860411,
     "end_time": "2022-06-18T15:45:35.457152",
     "exception": false,
     "start_time": "2022-06-18T15:45:33.596741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run parralell\n",
    "import pyblaze.multiprocessing as xmp\n",
    "import multiprocessing as mp\n",
    "mp.set_start_method('fork', force = True)\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ea2dca",
   "metadata": {
    "papermill": {
     "duration": 0.018674,
     "end_time": "2022-06-18T15:45:35.494868",
     "exception": false,
     "start_time": "2022-06-18T15:45:35.476194",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# .Process Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fdbc64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T15:45:35.534396Z",
     "iopub.status.busy": "2022-06-18T15:45:35.533497Z",
     "iopub.status.idle": "2022-06-18T15:45:35.551365Z",
     "shell.execute_reply": "2022-06-18T15:45:35.550759Z"
    },
    "papermill": {
     "duration": 0.040637,
     "end_time": "2022-06-18T15:45:35.553783",
     "exception": false,
     "start_time": "2022-06-18T15:45:35.513146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def valid(DTS, save):\n",
    "    print(\"\\nFound folder: \\n\",DTS)\n",
    "    clin= pd.read_csv(\n",
    "        \"/kaggle/input/colorectalcancer/\" + DTS + \"_clinicaldata.txt\", sep=\"\\t\", \n",
    "        index_col=\"!Sample_geo_accession\")\n",
    "    genes= pd.read_csv(\n",
    "        \"/kaggle/input/colorectalcancer/\" + DTS + \"_genes.txt\", sep=\"\\t\")\n",
    "\n",
    "    clin = clin.rename(columns={\"status\":\"target\"})\n",
    "    genes = genes.T\n",
    "    # print(type(genes))\n",
    "    genes = genes.rename(columns=genes.iloc[0]).drop(genes.index[0])\n",
    "    # data = data.join(clin.filter(regex=(target)))\n",
    "    # print(\"\\nHEADINGS\\n\" \n",
    "    #     , clin.head())\n",
    "    # print(\"\\nSUMMARY\\n\"\n",
    "    #     , clin.describe(include=['object']))\n",
    "    # print(\"\\nCOLUMN SUMMARY\\n\", clin['target'].value_counts(normalize=True))\n",
    "    # print(clin['target'].value_counts(normalize=True).items)\n",
    "\n",
    "            # except: \n",
    "            #     print(\"No found folder or file\")\n",
    "            #     pass\n",
    "\n",
    "    def classification_train(df):\n",
    "        if df[\"target\"] == \" colorectal cancer\":\n",
    "            return 1\n",
    "        elif (df[\"target\"] == \" normal\") | (df[\"target\"] == \" non-Cancer\"):\n",
    "            return 0\n",
    "        else:\n",
    "            return -1\n",
    "    def classification_DFS(df):\n",
    "        if df[\"DFS\"] == 1:\n",
    "            return True\n",
    "        elif df[\"DFS\"] == 0:\n",
    "            return False\n",
    "        else:\n",
    "            return \"NA\"\n",
    "\n",
    "    clin[\"target\"] = clin.apply(classification_train, axis=1)\n",
    "    clin[\"DFS\"] = clin.apply(classification_DFS, axis=1)\n",
    "    # print(\"\\nTARGET in CLIN\\n\" \n",
    "    #     , clin[\"target\"])\n",
    "    print(pd.DataFrame(clin['target'].value_counts(normalize=True)).iloc[0, 0])\n",
    "    print(clin['target'].count())\n",
    "    # AUC(clin = clin, genes = genes, output = DTS, method = \"Standard\")\n",
    "    data = genes.join(clin.filter(regex=(\"target\")))\n",
    "    data = data.join(clin.filter(regex=(\"DFS\")))\n",
    "    data = data.join(clin.filter(regex=(\"stage\")))   \n",
    "    print(data)\n",
    "    if save == True:\n",
    "        dir = os.path.join(\"/content/drive/MyDrive/THESIS/machine-learning/processed_data\",DTS)\n",
    "        print(dir)\n",
    "        if not os.path.exists(dir):\n",
    "            os.mkdir(dir)\n",
    "        print(\"\\nSaving...\\n\")\n",
    "        data.to_csv(dir +\"/processed_data_\"+DTS +\".txt\", sep=\"\\t\")\n",
    "        print(\"\\nDone!\\n\")\n",
    "    elif save == False:\n",
    "        pass\n",
    "    return(data)\n",
    "\n",
    "def train(DTS, save):\n",
    "    print(\"\\nFound folder: \\n\",DTS)\n",
    "    clin= pd.read_csv(\n",
    "        \"/kaggle/input/colorectalcancer/\" + DTS + \"_clinicaldata.txt\", sep=\"\\t\", \n",
    "        index_col=\"!Sample_geo_accession\")\n",
    "    genes= pd.read_csv(\n",
    "        \"/kaggle/input/colorectalcancer/\" + DTS + \"_genes.txt\", sep=\"\\t\")\n",
    "\n",
    "    clin = clin.rename(columns={\"status\":\"target\"})\n",
    "    genes = genes.T\n",
    "    # print(type(genes))\n",
    "    genes = genes.rename(columns=genes.iloc[0]).drop(genes.index[0])\n",
    "    # data = data.join(clin.filter(regex=(target)))\n",
    "    # print(\"\\nHEADINGS\\n\" \n",
    "    #     , clin.head())\n",
    "    # print(\"\\nSUMMARY\\n\"\n",
    "    #     , clin.describe(include=['object']))\n",
    "    # print(\"\\nCOLUMN SUMMARY\\n\", clin['target'].value_counts(normalize=True))\n",
    "    # print(clin['target'].value_counts(normalize=True).items)\n",
    "\n",
    "            # except: \n",
    "            #     print(\"No found folder or file\")\n",
    "            #     pass\n",
    "\n",
    "    def classification_train(df):\n",
    "        if df[\"target\"] == \" colorectal cancer\":\n",
    "            return 1\n",
    "        elif (df[\"target\"] == \" normal\") | (df[\"target\"] == \" non-Cancer\"):\n",
    "            return 0\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "    clin[\"target\"] = clin.apply(classification_train, axis=1)\n",
    "    # print(\"\\nTARGET in CLIN\\n\" \n",
    "    #     , clin[\"target\"])\n",
    "    print(pd.DataFrame(clin['target'].value_counts(normalize=True)).iloc[0, 0])\n",
    "    print(clin['target'].count())\n",
    "    # AUC(clin = clin, genes = genes, output = DTS, method = \"Standard\")\n",
    "    data = genes.join(clin.filter(regex=(\"target\")))\n",
    "    print(data)\n",
    "    if save == True:\n",
    "        dir = os.path.join(\"/content/drive/MyDrive/THESIS/machine-learning/processed_data/processed_data\",DTS)\n",
    "        print(dir)\n",
    "        if not os.path.exists(dir):\n",
    "            os.mkdir(dir)\n",
    "        print(\"\\nSaving...\\n\")\n",
    "        data.to_csv(dir +\"/processed_data_\"+DTS +\".txt\", sep=\"\\t\")\n",
    "        print(\"\\nDone!\\n\")\n",
    "    elif save == False:\n",
    "        pass\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe58619",
   "metadata": {
    "papermill": {
     "duration": 0.017106,
     "end_time": "2022-06-18T15:45:35.588588",
     "exception": false,
     "start_time": "2022-06-18T15:45:35.571482",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# .Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5b7d55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T15:45:35.627359Z",
     "iopub.status.busy": "2022-06-18T15:45:35.626814Z",
     "iopub.status.idle": "2022-06-18T15:45:35.658812Z",
     "shell.execute_reply": "2022-06-18T15:45:35.657839Z"
    },
    "papermill": {
     "duration": 0.05498,
     "end_time": "2022-06-18T15:45:35.661270",
     "exception": false,
     "start_time": "2022-06-18T15:45:35.606290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import functools\n",
    "import numpy as np\n",
    "import torch.multiprocessing as mp\n",
    "from pyblaze.utils.stdmp import terminate\n",
    "from tqdm import tqdm\n",
    "class Vectorizer:\n",
    "    \"\"\"\n",
    "    The Vectorizer class ought to be used in cases where a result tensor of size N is filled with\n",
    "    values computed in some complex way. The computation of these N computations can then be\n",
    "    parallelized over multiple processes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, worker_func, worker_init=None, callback_func=None, num_workers=-1, **kwargs):\n",
    "        \"\"\"\n",
    "        Initializes a new vectorizer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        worker_func: callable\n",
    "            The function which receives as input an item of the input to process and outputs a\n",
    "            value which ought to be returned.\n",
    "        worker_init: callable, default: None\n",
    "            The function receives as input the rank of the worker (i.e. every time this function is\n",
    "            called, it is called with a different integer as parameter). Its return values are\n",
    "            passed as *last* parameters to `worker_func` upon every invocation.\n",
    "        callback_func: callable, default: None\n",
    "            A function to call after every item has been processed. Must not need to be a free\n",
    "            function as it is called on the main thread.\n",
    "        num_workers: int, default: -1\n",
    "            The number of processes to use. If set to -1, it defaults to the number of available\n",
    "            cores. If set to 0, everything is executed on the main thread.\n",
    "        kwargs: keyword arguments\n",
    "            Additional arguments passed to the worker initialization function.\n",
    "        \"\"\"\n",
    "        self.num_workers = os.cpu_count() if num_workers == -1 else num_workers\n",
    "        self.worker_func = worker_func\n",
    "        self.worker_init = worker_init\n",
    "        self.callback_func = callback_func\n",
    "        self.init_kwargs = kwargs\n",
    "        self._shutdown_fn = None\n",
    "\n",
    "    def process(self, items, *args):\n",
    "        \"\"\"\n",
    "        Uses the vectorizer's worker function in order to process all items in parallel.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        items: list of object or iterable of object\n",
    "            The items to be processed by the workers. If given as iterable only (i.e. it does not\n",
    "            support index access), the performance might suffer slightly due to an increased number\n",
    "            of synchronizations.\n",
    "        args: variadic arguments\n",
    "            Additional arguments passed directly to the worker function.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list of object\n",
    "            The output generated by the worker function for each of the input items.\n",
    "        \"\"\"\n",
    "        if self.num_workers == 0: # execute sequentially\n",
    "            result = []\n",
    "            init = _init_if_needed(self.worker_init, 0, **self.init_kwargs)\n",
    "            all_args = _combine_args(args, init)\n",
    "            for item in items:\n",
    "                result.append(self.worker_func(item, *all_args))\n",
    "            return result\n",
    "\n",
    "        process_batches = hasattr(items, '__getitem__')\n",
    "\n",
    "        if process_batches:\n",
    "            result = self._process_batches(items, *args)\n",
    "        else:\n",
    "            result = self._process_consumers(items, *args)\n",
    "\n",
    "        self._shutdown_fn()\n",
    "        self._shutdown_fn = None\n",
    "        return result\n",
    "\n",
    "    def _process_batches(self, items, *args):\n",
    "        num_items = len(items)\n",
    "\n",
    "        splits = np.array_split(np.arange(num_items), self.num_workers)\n",
    "        splits = [0] + [a[-1] + 1 for a in splits]\n",
    "\n",
    "        result = []\n",
    "\n",
    "        processes = []\n",
    "        queues = []\n",
    "        done = mp.Event()\n",
    "        if self.callback_func is not None:\n",
    "            tick_queue = mp.Queue()\n",
    "        else:\n",
    "            tick_queue = None\n",
    "        \n",
    "        for i in range(self.num_workers):\n",
    "            queue = mp.Queue()\n",
    "            process = mp.Process(\n",
    "                target=_batch_worker,\n",
    "                args=(\n",
    "                    queue, done, tick_queue, i,\n",
    "                    self.worker_func, self.worker_init, self.init_kwargs,\n",
    "                    items[splits[i]:splits[i+1]], *args\n",
    "                )\n",
    "            )\n",
    "            process.daemon = True\n",
    "            process.start()\n",
    "            \n",
    "            processes.append(process)\n",
    "            queues.append(queue)\n",
    "\n",
    "        self._shutdown_fn = functools.partial(\n",
    "            self._shutdown_batches, processes, done\n",
    "        )\n",
    "\n",
    "        if self.callback_func is not None:\n",
    "            for _ in range(num_items):\n",
    "                tick_queue.get()\n",
    "                self.callback_func()\n",
    "\n",
    "        for i, q in enumerate(queues):\n",
    "            result.extend(q.get())\n",
    "            q.close()\n",
    "\n",
    "        return result\n",
    "\n",
    "    def _shutdown_batches(self, processes, done):\n",
    "        done.set()\n",
    "        terminate(*processes)\n",
    "\n",
    "    def _process_consumers(self, items, *args):\n",
    "        result = []\n",
    "\n",
    "        processes = []\n",
    "        push_queue = mp.Queue()\n",
    "        pull_queue = mp.Queue()\n",
    "\n",
    "        for i in range(self.num_workers):\n",
    "            process = mp.Process(\n",
    "                target=_consumer_worker,\n",
    "                args=(push_queue, pull_queue, i,\n",
    "                      self.worker_func, self.worker_init, self.init_kwargs,\n",
    "                      *args)\n",
    "            )\n",
    "            process.daemon = True\n",
    "            process.start()\n",
    "            print(\"\\nProcessor \", i, \"...\\n\")\n",
    "            processes.append(process)\n",
    "\n",
    "        self._shutdown_fn = functools.partial(\n",
    "            self._shutdown_consumers, processes, pull_queue, push_queue\n",
    "        )\n",
    "\n",
    "        iterator = iter(items)\n",
    "        index = 0\n",
    "        expect = 0\n",
    "        try:\n",
    "            for _ in range(self.num_workers):\n",
    "                item = next(iterator)\n",
    "                expect += 1\n",
    "                push_queue.cancel_join_thread()\n",
    "                push_queue.put((index, item))\n",
    "                index += 1\n",
    "\n",
    "            while True:\n",
    "                result.append(pull_queue.get())\n",
    "                if self.callback_func is not None:\n",
    "                    self.callback_func()\n",
    "                expect -= 1\n",
    "                item = next(iterator)\n",
    "                expect += 1\n",
    "                push_queue.cancel_join_thread()\n",
    "                push_queue.put((index, item))\n",
    "                index += 1\n",
    "\n",
    "        except StopIteration:\n",
    "            for _ in range(expect):\n",
    "                result.append(pull_queue.get())\n",
    "                if self.callback_func is not None:\n",
    "                    self.callback_func()\n",
    "\n",
    "        return [r[1] for r in sorted(result, key=lambda r: r[0])]\n",
    "\n",
    "    def _shutdown_consumers(self, processes, pull_queue, push_queue):\n",
    "        pull_queue.close()\n",
    "\n",
    "        for _ in range(len(processes)):\n",
    "            push_queue.cancel_join_thread()\n",
    "            push_queue.put(None)\n",
    "\n",
    "        push_queue.close()\n",
    "\n",
    "        terminate(*processes)\n",
    "\n",
    "    def __del__(self):\n",
    "        if self._shutdown_fn is not None:\n",
    "            self._shutdown_fn()\n",
    "\n",
    "\n",
    "def _batch_worker(push_queue, done, tick_queue, rank,\n",
    "                  worker_func, worker_init, init_kwargs, items, *args):\n",
    "    init = _init_if_needed(worker_init, rank, **init_kwargs)\n",
    "    all_args = _combine_args(args, init)\n",
    "    result = []\n",
    "    if rank == 1 :\n",
    "        pbar = tqdm(total = len(items), desc = \">>Processor \" + str(rank))\n",
    "    else: pbar = tqdm(total = len(items), desc = \">>Processor \" + str(rank), disable = True)\n",
    "    for item in items:\n",
    "        pbar.update(1)\n",
    "        result.append(worker_func(item, *all_args))\n",
    "        if tick_queue is not None:\n",
    "            tick_queue.cancel_join_thread()\n",
    "            tick_queue.put(None)\n",
    "    push_queue.cancel_join_thread()\n",
    "    push_queue.put(result)\n",
    "    done.wait()\n",
    "\n",
    "\n",
    "def _consumer_worker(pull_queue, push_queue, rank, worker_func, worker_init, init_kwargs, *args):\n",
    "\n",
    "    init = _init_if_needed(worker_init, rank, **init_kwargs)\n",
    "    all_args = _combine_args(args, init)\n",
    "\n",
    "    while True:\n",
    "        item = pull_queue.get()\n",
    "        if item is None:\n",
    "            break\n",
    "\n",
    "        idx, item = item\n",
    "        result = worker_func(item, *all_args)\n",
    "\n",
    "        push_queue.cancel_join_thread()\n",
    "        push_queue.put((idx, result))\n",
    "\n",
    "\n",
    "def _init_if_needed(init, rank, **kwargs):\n",
    "    if init is None:\n",
    "        return None\n",
    "    return init(rank, **kwargs)\n",
    "\n",
    "\n",
    "def _combine_args(a, b):\n",
    "    if b is None:\n",
    "        return a\n",
    "    if isinstance(b, tuple):\n",
    "        return a + b\n",
    "    return a + (b,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9cb725",
   "metadata": {
    "papermill": {
     "duration": 0.019727,
     "end_time": "2022-06-18T15:45:35.699130",
     "exception": false,
     "start_time": "2022-06-18T15:45:35.679403",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# .Choose DTS and path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca60aca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T15:45:35.736257Z",
     "iopub.status.busy": "2022-06-18T15:45:35.735811Z",
     "iopub.status.idle": "2022-06-18T15:45:35.741250Z",
     "shell.execute_reply": "2022-06-18T15:45:35.740299Z"
    },
    "papermill": {
     "duration": 0.026533,
     "end_time": "2022-06-18T15:45:35.743301",
     "exception": false,
     "start_time": "2022-06-18T15:45:35.716768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainDTS=\"GSE164191\"\n",
    "validationDTS=\"GSE39582\"\n",
    "suffix = \"\"\n",
    "path=\"/kaggle/working/output\"\n",
    "dts = {\"train\":trainDTS, \"validation\":validationDTS}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a99bd2b",
   "metadata": {
    "papermill": {
     "duration": 0.020197,
     "end_time": "2022-06-18T15:45:35.782105",
     "exception": false,
     "start_time": "2022-06-18T15:45:35.761908",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# .Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7349b67b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T15:45:35.823876Z",
     "iopub.status.busy": "2022-06-18T15:45:35.822293Z",
     "iopub.status.idle": "2022-06-18T15:45:42.764221Z",
     "shell.execute_reply": "2022-06-18T15:45:42.763086Z"
    },
    "papermill": {
     "duration": 6.965306,
     "end_time": "2022-06-18T15:45:42.767001",
     "exception": false,
     "start_time": "2022-06-18T15:45:35.801695",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train(dts[\"train\"], save = False).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de32a9d",
   "metadata": {
    "papermill": {
     "duration": 0.018436,
     "end_time": "2022-06-18T15:45:42.804623",
     "exception": false,
     "start_time": "2022-06-18T15:45:42.786187",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# .Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706ef8fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T15:45:42.843200Z",
     "iopub.status.busy": "2022-06-18T15:45:42.842839Z",
     "iopub.status.idle": "2022-06-18T15:46:19.549419Z",
     "shell.execute_reply": "2022-06-18T15:46:19.546669Z"
    },
    "papermill": {
     "duration": 36.730432,
     "end_time": "2022-06-18T15:46:19.553565",
     "exception": false,
     "start_time": "2022-06-18T15:45:42.823133",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation = valid(dts[\"validation\"], save = False).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a1c485",
   "metadata": {
    "papermill": {
     "duration": 0.02008,
     "end_time": "2022-06-18T15:46:19.594261",
     "exception": false,
     "start_time": "2022-06-18T15:46:19.574181",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# .Choose characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e5475a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T15:46:19.640496Z",
     "iopub.status.busy": "2022-06-18T15:46:19.639851Z",
     "iopub.status.idle": "2022-06-18T15:46:19.648724Z",
     "shell.execute_reply": "2022-06-18T15:46:19.646841Z"
    },
    "papermill": {
     "duration": 0.036452,
     "end_time": "2022-06-18T15:46:19.652336",
     "exception": false,
     "start_time": "2022-06-18T15:46:19.615884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# top features with highest score\n",
    "number_of_features = 200\n",
    "# The test size you want to split from train_test rang from (0:1), for large data chooose 0.1, smaller try 0.2-0.4\n",
    "test_size = 0.5\n",
    "# Method for scale data, if equal to Standard it will be z-score normalization else will be MinMaxScaler\n",
    "method = \"Standard\"\n",
    "# num_folds= number of fold validation which mean it will validation on the training data by 5 subset training, should be 5 or 10 if data is larger\n",
    "number_of_folds = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c05b664",
   "metadata": {
    "papermill": {
     "duration": 0.020294,
     "end_time": "2022-06-18T15:46:19.694372",
     "exception": false,
     "start_time": "2022-06-18T15:46:19.674078",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    ">>>*Combination Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14397fbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T15:46:19.739977Z",
     "iopub.status.busy": "2022-06-18T15:46:19.739328Z",
     "iopub.status.idle": "2022-06-18T15:46:19.746714Z",
     "shell.execute_reply": "2022-06-18T15:46:19.745661Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.032911,
     "end_time": "2022-06-18T15:46:19.749634",
     "exception": false,
     "start_time": "2022-06-18T15:46:19.716723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Section 3: Making combination inputs\n",
    "def combinations(features, combinations):\n",
    "    features = list(itertools.combinations(features, combinations))\n",
    "    return features\n",
    "\n",
    "# Model name\n",
    "def model_name(selected_features):\n",
    "    return ' '.join(selected_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d3be09",
   "metadata": {
    "papermill": {
     "duration": 0.022143,
     "end_time": "2022-06-18T15:46:19.791598",
     "exception": false,
     "start_time": "2022-06-18T15:46:19.769455",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    ">>>*Parameter tuning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b604cffc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T15:46:19.837442Z",
     "iopub.status.busy": "2022-06-18T15:46:19.836908Z",
     "iopub.status.idle": "2022-06-18T15:46:19.939751Z",
     "shell.execute_reply": "2022-06-18T15:46:19.937926Z"
    },
    "papermill": {
     "duration": 0.129624,
     "end_time": "2022-06-18T15:46:19.943432",
     "exception": false,
     "start_time": "2022-06-18T15:46:19.813808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parameter_tuning(value, path):\n",
    "    X_train, X_test, X_valid = value[0], value[1], value[2]\n",
    "    y_train, y_test, y_valid = value[3], value[4], value[5]\n",
    "    num_folds, feature_name = value[6], value[7]\n",
    "    y_valid2 = value[8]\n",
    "    y_dfs = value[9]\n",
    "    # Create models\n",
    "    # Model 4\n",
    "    log_reg_params = dict(class_weight=['balanced', None], solver=[\n",
    "                          'newton-cg', 'lbfgs', 'liblinear', 'sag'], fit_intercept=[True, False])\n",
    "    # # Create the model\n",
    "    params = [\n",
    "         log_reg_params]\n",
    "    # classifiers to test\n",
    "    classifiers = [\n",
    "        LogisticRegression()]\n",
    "\n",
    "    names = [\n",
    "        'LogisticRegression']\n",
    "    models = dict(zip(names, zip(classifiers, params)))\n",
    "    # print(num_folds, 'fold cross-validation is used')\n",
    "    results_train_train = []\n",
    "    results_train_test = []\n",
    "    results_train_valid = []\n",
    "    # dataframe to store intermediate results\n",
    "    for name, clf_and_params in models.items():\n",
    "        clf, clf_params = clf_and_params\n",
    "        # Handling error when the features is not come up with models\n",
    "        try:\n",
    "            # print('Computing GridSearch on {} '.format(name))\n",
    "            clf, clf_params = clf_and_params\n",
    "            # Parameter and training\n",
    "            grid_clf = GridSearchCV(\n",
    "                estimator=clf, param_grid=clf_params, cv=num_folds, refit= \"accuracy\", scoring = performance)\n",
    "            grid_clf = grid_clf.fit(X_train, y_train)\n",
    "            # Train\n",
    "            perform_train = performance(grid_clf, X_train, y_train)\n",
    "\n",
    "            # Testing\n",
    "            perform_test = performance(grid_clf, X_test, y_test)\n",
    "            # Validation\n",
    "            perform_valid = performance(grid_clf, X_valid, y_valid)\n",
    "\n",
    "            cv_scores = cross_val_score(clf, X_train, y_train, cv=num_folds)\n",
    "            coef = grid_clf.best_estimator_.coef_\n",
    "            intercept = grid_clf.best_estimator_.intercept_\n",
    "            # Performance\n",
    "            perform_train.update({\"cv\": np.mean(cv_scores), \"name\": feature_name,\n",
    "                                \"model_name\": name, \"best_params\": grid_clf.best_params_\n",
    "                                , \"coef\": coef, \"intercept\": intercept\n",
    "                                })\n",
    "            perform_valid.update({\"cv\": np.mean(cv_scores), \"name\": feature_name,\n",
    "                                \"model_name\": name, \"best_params\": grid_clf.best_params_\n",
    "                                , \"coef\": coef, \"intercept\": intercept\n",
    "                                })\n",
    "            perform_test.update({\"cv\": np.mean(cv_scores), \"name\": feature_name,\n",
    "                                \"model_name\": name, \"best_params\": grid_clf.best_params_\n",
    "                                , \"coef\": coef, \"intercept\": intercept\n",
    "                                })\n",
    "\n",
    "            # Results\n",
    "            results_train_train.append(perform_train)\n",
    "            results_train_test.append(perform_test)\n",
    "            results_train_valid.append(perform_valid)\n",
    "            \n",
    "        except:\n",
    "            print(\"An exception occurred\")\n",
    "            pass\n",
    "    e = math.e\n",
    "    X = 1/(1 + pow(e,-np.sum(X_valid*coef, axis = 1) + intercept))\n",
    "    stage = y_valid2\n",
    "    data = pd.DataFrame({\"gene\": X, \"stage\": stage})\n",
    "    aa = data[data[\"stage\"] == 1]\n",
    "    bb = data[data[\"stage\"] == 2]\n",
    "    cc = data[data[\"stage\"] == 3]\n",
    "    dd = data[data[\"stage\"] == 4]\n",
    "    a = s.mean(aa[\"gene\"])\n",
    "    b = s.mean(bb[\"gene\"])\n",
    "    c = s.mean(cc[\"gene\"])\n",
    "    d = s.mean(dd[\"gene\"])\n",
    "    f, p = stats.f_oneway(aa[\"gene\"],\n",
    "                bb[\"gene\"],\n",
    "                cc[\"gene\"], dd[\"gene\"])\n",
    "    group_indicator= pd.DataFrame(X) < np.median(pd.DataFrame(X))\n",
    "    chisq, pvalue = compare_survival(y_dfs, group_indicator)\n",
    "    if (a <= b <= c <= d) | (a >= b >= c >= d):\n",
    "        if p <= 0.05:\n",
    "            if pvalue <= 0.05:\n",
    "                pd.DataFrame(results_train_train).to_csv(\n",
    "                    path + \"/\" +str(feature_name)+\"_train.csv\", index=False)\n",
    "                pd.DataFrame(results_train_test).to_csv(\n",
    "                    path+ \"/\"+str(feature_name)+\"_test.csv\", index=False)\n",
    "                pd.DataFrame(results_train_valid).to_csv(\n",
    "                    path+ \"/\"+str(feature_name)+\"_validation.csv\", index=False)\n",
    "            else: print(feature_name, \" Kmp not satisfied\")\n",
    "        else: print(feature_name, \" Anv violin plot not satisfied\")\n",
    "    else: print(feature_name, \" Vp not satisfied\")\n",
    "#     print(feature_name)\n",
    "\n",
    "# Get the combination of features all\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381d60db",
   "metadata": {
    "papermill": {
     "duration": 0.020003,
     "end_time": "2022-06-18T15:46:19.984543",
     "exception": false,
     "start_time": "2022-06-18T15:46:19.964540",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    ">>>*Performance*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1a7ecd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T15:46:20.033129Z",
     "iopub.status.busy": "2022-06-18T15:46:20.032462Z",
     "iopub.status.idle": "2022-06-18T15:46:20.047661Z",
     "shell.execute_reply": "2022-06-18T15:46:20.046412Z"
    },
    "papermill": {
     "duration": 0.044087,
     "end_time": "2022-06-18T15:46:20.050932",
     "exception": false,
     "start_time": "2022-06-18T15:46:20.006845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def performance(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    accuracy = (tp+tn)/(tn+fp+fn+tp)\n",
    "    sensitivity = tp/(tp+fn)\n",
    "    specificity = tn/(tn+fp)\n",
    "    PPV = tp/(tp+fp)\n",
    "    NPV = tn/(tn+fn)\n",
    "    f1 = metrics.f1_score(y, y_pred)\n",
    "    kappa = metrics.cohen_kappa_score(y, y_pred)\n",
    "    try:\n",
    "        # Calculate area under curve (AUC)\n",
    "        y_pred_proba = model.predict_proba(X)[::, 1]\n",
    "        auc = metrics.roc_auc_score(y, y_pred_proba)\n",
    "    except:\n",
    "        auc = \"NA\"\n",
    "    return {\"accuracy\": accuracy, \"sensitivity\": sensitivity, \"specificity\": specificity, \"auc\": auc, \"PPV\": PPV, \"NPV\": NPV, \"f1\": f1, \"kappa\": kappa}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d340048c",
   "metadata": {
    "papermill": {
     "duration": 0.021065,
     "end_time": "2022-06-18T15:46:20.094225",
     "exception": false,
     "start_time": "2022-06-18T15:46:20.073160",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    ">>>*Data Prepare Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdec0e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T15:46:20.139143Z",
     "iopub.status.busy": "2022-06-18T15:46:20.138689Z",
     "iopub.status.idle": "2022-06-18T15:46:20.150235Z",
     "shell.execute_reply": "2022-06-18T15:46:20.149538Z"
    },
    "papermill": {
     "duration": 0.036795,
     "end_time": "2022-06-18T15:46:20.152938",
     "exception": false,
     "start_time": "2022-06-18T15:46:20.116143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_prepare(train_test, validation, num_folds, selected_features, test_size, method):\n",
    "    FeatureName = selected_features\n",
    "    models = []\n",
    "    dt = np.dtype([('DFS', np.bool_), ('DFSM', np.float64)])\n",
    "    y_dfs = np.array([],dtype=dt)\n",
    "    for i in tqdm(range(0, validation.shape[0])):\n",
    "        y_dfs = np.append(y_dfs, np.array([(validation.loc[validation.index[i], 'DFS'],\n",
    "                        validation.loc[validation.index[i], 'DFSM'])], dtype=dt))\n",
    "    for i in tqdm(FeatureName, desc = \"Processing...\"):\n",
    "        feature_name = i.split(\"-\")\n",
    "        selected_features = []\n",
    "        for k in feature_name:\n",
    "            selected_features.append(k)\n",
    "        selected_features.append(\"target\")\n",
    "#         print(\"Processing on:\", i)\n",
    "        data1 = train_test[selected_features]\n",
    "        data2 = validation[selected_features]\n",
    "        # Splitting the data\n",
    "        y = data1[\"target\"]\n",
    "        X = data1.drop([\"target\"], axis=1)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "        # Transformation\n",
    "        if method == \"Standard\":\n",
    "            scaler = StandardScaler()\n",
    "        else:\n",
    "            scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "        X_test = scaler.transform(X_test)\n",
    "        # Validation\n",
    "        X_valid = data2.drop([\"target\"], axis=1)\n",
    "        X_valid = scaler.fit_transform(X_valid)\n",
    "        y_valid = data2[\"target\"]\n",
    "        y_valid2 = validation[\"stage\"]\n",
    "        \n",
    "        models.append([X_train, X_test, X_valid, y_train,\n",
    "                      y_test, y_valid, num_folds, i, y_valid2, y_dfs])\n",
    "    return models\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fab216",
   "metadata": {
    "papermill": {
     "duration": 0.020739,
     "end_time": "2022-06-18T15:46:20.195465",
     "exception": false,
     "start_time": "2022-06-18T15:46:20.174726",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    ">>>*Multiprocess Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d3d0f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T15:46:20.238881Z",
     "iopub.status.busy": "2022-06-18T15:46:20.237884Z",
     "iopub.status.idle": "2022-06-18T15:46:20.244238Z",
     "shell.execute_reply": "2022-06-18T15:46:20.243245Z"
    },
    "papermill": {
     "duration": 0.029881,
     "end_time": "2022-06-18T15:46:20.246373",
     "exception": false,
     "start_time": "2022-06-18T15:46:20.216492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parallel(value, output, num_workers):\n",
    "    tokenizer = Vectorizer(worker_func=parameter_tuning, num_workers=num_workers, worker_init=None, callback_func=None)\n",
    "    return tokenizer.process(value, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e444e70",
   "metadata": {
    "papermill": {
     "duration": 0.019849,
     "end_time": "2022-06-18T15:46:20.285901",
     "exception": false,
     "start_time": "2022-06-18T15:46:20.266052",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# .Data Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e54ea02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T15:46:20.328963Z",
     "iopub.status.busy": "2022-06-18T15:46:20.328324Z",
     "iopub.status.idle": "2022-06-18T15:46:20.477016Z",
     "shell.execute_reply": "2022-06-18T15:46:20.476184Z"
    },
    "papermill": {
     "duration": 0.171881,
     "end_time": "2022-06-18T15:46:20.479601",
     "exception": false,
     "start_time": "2022-06-18T15:46:20.307720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a list of features\n",
    "import os\n",
    "file = os.listdir(\"/kaggle/working/feature\")\n",
    "file\n",
    "featurelist = open(\"/kaggle/working/feature/featurelist.txt\", \"r\").read().split(\".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16671943",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T15:46:20.520256Z",
     "iopub.status.busy": "2022-06-18T15:46:20.519474Z",
     "iopub.status.idle": "2022-06-18T15:46:20.537109Z",
     "shell.execute_reply": "2022-06-18T15:46:20.536061Z"
    },
    "papermill": {
     "duration": 0.041337,
     "end_time": "2022-06-18T15:46:20.539217",
     "exception": false,
     "start_time": "2022-06-18T15:46:20.497880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Feature Function\n",
    "def getfeature(featurelist, used, numberoffeature):\n",
    "    selected_features = random.sample([item for item in featurelist\n",
    "                                if item not in used]\n",
    "                                     , numberoffeature)\n",
    "    used = used + selected_features\n",
    "    with open('/kaggle/working/used/used.txt', 'w') as f:\n",
    "        f.write(\".\".join(used))\n",
    "    !git -C \"/kaggle/working/used\" add used.txt\n",
    "    message = str(len(featurelist)-len(used)) + \" features remaining\"\n",
    "    !git -C \"/kaggle/working/used\" commit -m \"$message\"\n",
    "    !git -C \"/kaggle/working/used\" push origin master\n",
    "    return(selected_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c356a92c",
   "metadata": {
    "papermill": {
     "duration": 0.011637,
     "end_time": "2022-06-18T15:46:20.562723",
     "exception": false,
     "start_time": "2022-06-18T15:46:20.551086",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1e46c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-18T15:46:20.589764Z",
     "iopub.status.busy": "2022-06-18T15:46:20.589048Z",
     "iopub.status.idle": "2022-06-18T15:56:18.575395Z",
     "shell.execute_reply": "2022-06-18T15:56:18.572770Z"
    },
    "papermill": {
     "duration": 598.004117,
     "end_time": "2022-06-18T15:56:18.578875",
     "exception": false,
     "start_time": "2022-06-18T15:46:20.574758",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "print(\"\\nPREPARING DATA...\\n\")\n",
    "for i in range(0, 1000):\n",
    "    !git -C \"/kaggle/working/used\" pull\n",
    "    used = open(\"/kaggle/working/used/used.txt\", \"r\").read().split(\".\")\n",
    "    done = open(\"/kaggle/working/used/ml1done.txt\", \"r\").read().split(\".\") #\n",
    "    if len(featurelist) != len(used):\n",
    "        selected_features = getfeature(featurelist, used, 1000)\n",
    "        # 02. Prepare data\n",
    "        all_inputs = data_prepare(\n",
    "            train, validation,  number_of_folds, selected_features, test_size, method)\n",
    "\n",
    "        # Machine learning\n",
    "        print(\"\\nSTART MACHINE LEARNING...\\n\")\n",
    "        mp.set_start_method('fork', force = True)\n",
    "        if __name__ == '__main__':\n",
    "            parallel(\n",
    "                all_inputs, path, -1)\n",
    "        !git -C \"/kaggle/working/output\" add -A\n",
    "        !git -C \"/kaggle/working/output\" commit -m \"add results\"\n",
    "        !git -C \"/kaggle/working/output\" push origin master\n",
    "        print(\"Done\")\n",
    "        done = done + selected_features\n",
    "        with open('/kaggle/working/used/ml1done.txt', 'w') as f: #\n",
    "            f.write(\".\".join(used))\n",
    "        !git -C \"/kaggle/working/used\" add ml1done.txt #\n",
    "        !git -C \"/kaggle/working/used\" commit -m \"update ml1\" #\n",
    "        !git -C \"/kaggle/working/used\" push origin master\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 690.71796,
   "end_time": "2022-06-18T15:56:21.807712",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-18T15:44:51.089752",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
